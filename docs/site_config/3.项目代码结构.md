# 项目代码结构

本文档详细说明Visual_MediaCrawler项目的代码结构和各模块功能。

## 项目总体架构

Visual_MediaCrawler采用前后端分离的架构设计：

- **前端**：基于Vue.js和Vite构建的Web界面，提供数据爬取和数据展示功能
- **后端**：基于FastAPI构建的API服务，提供爬虫任务管理和数据处理功能
- **数据存储**：支持SQLite和MySQL双数据库存储

## 项目结构

```
Visual_MediaCrawler/
├── api/                     # FastAPI 应用主文件和API相关逻辑
│   ├── api.py              # 主API服务文件
│   ├── extra_sqlite_api.py # SQLite数据库API扩展
│   ├── extra_mysql_api.py  # MySQL数据库API扩展
│   ├── static_page_api.py # 静态页面API扩展
│   ├── api_run.bat         # API服务启动脚本
│   └── README.md           # API服务说明文档
├── dp_op/                   # 数据库操作模块
│   ├── async_mysql_db.py   # 异步 MySQL 数据库操作封装
│   ├── async_sqlite_db.py  # 异步 SQLite 数据库操作封装
│   └── db_tables_mapping.py   # 数据库表映射封装
├── base/                    # 基础爬虫模块
│   └── base_crawler.py     # 爬虫基类
├── browser_data/            # 浏览器用户数据目录（仅爬取进行时产生并存在）
├── cache/                   # 缓存模块
│   ├── abs_cache.py        # 抽象缓存类
│   ├── cache_factory.py    # 缓存工厂
│   ├── local_cache.py      # 本地缓存实现
│   └── redis_cache.py      # Redis缓存实现
├── cmd_arg/                 # 命令行参数处理
│   └── arg.py              # 参数解析器
├── config/                  # 项目配置，包括数据库配置、基础配置等
│   ├── base_config.py      # 基础配置
│   └── db_config.py        # 数据库配置
├── constant/                # 常量定义
│   ├── baidu_tieba.py      # 百度贴吧常量
│   └── zhihu.py            # 知乎常量
├── data/                    # 爬取数据存储目录
│   ├── bilibili/           # B站数据
│   └── douyin/             # 抖音数据
├── db_init.py                    # 数据库初始化脚本
├── debug_tools/             # 调试工具
├── frontend/                # 前端服务代码
│   ├── src/                # 前端源码
│   │   ├── api/            # API接口封装
│   │   ├── components/     # Vue组件
│   │   └── views/          # 页面视图
│   ├── public/             # 静态资源
│   ├── index.html          # 入口HTML文件
│   ├── package.json        # 前端依赖配置
│   ├── vite.config.js      # Vite配置
│   └── frontend_run_dev.bat # 前端开发服务启动脚本
├── libs/                    # 第三方库或自定义工具库
│   ├── douyin.js           # 抖音相关JS库
│   ├── stealth.min.js      # 反检测库
│   └── zhihu.js            # 知乎相关JS库
├── main.py                  # 爬虫主入口
├── media_platform/          # 各媒体平台爬虫实现
│   ├── bilibili/           # B站爬虫
│   ├── douyin/             # 抖音爬虫
│   ├── kuaishou/           # 快手爬虫
│   ├── tieba/              # 百度贴吧爬虫
│   ├── weibo/              # 微博爬虫
│   ├── xhs/                # 小红书爬虫
│   └── zhihu/              # 知乎爬虫
├── model/                   # 数据模型定义
│   ├── m_baidu_tieba.py    # 百度贴吧数据模型
│   ├── m_douyin.py         # 抖音数据模型
│   ├── m_kuaishou.py       # 快手数据模型
│   ├── m_weibo.py          # 微博数据模型
│   ├── m_xiaohongshu.py    # 小红书数据模型
│   └── m_zhihu.py          # 知乎数据模型
├── proxy/                   # 代理相关配置和实现
│   ├── base_proxy.py       # 代理基类
│   ├── providers/          # 代理提供商
│   ├── proxy_ip_pool.py    # 代理IP池
│   └── types.py            # 代理类型定义
├── schema/                  # 数据库表结构定义
│   ├── sqlite_tables.db    # SQLite表结构数据库
│   ├── sqlite_tables.sql   # SQLite表结构SQL
│   └── mysql_tables.sql    # MySQL表结构SQL
├── store/                   # 数据存储逻辑
│   ├── bilibili/           # B站数据存储
│   ├── douyin/             # 抖音数据存储
│   ├── kuaishou/           # 快手数据存储
│   ├── tieba/              # 百度贴吧数据存储
│   ├── weibo/              # 微博数据存储
│   ├── xhs/                # 小红书数据存储
│   └── zhihu/              # 知乎数据存储
├── test/                    # 测试文件
│   ├── test_expiring_local_cache.py # 本地缓存测试
│   ├── test_proxy_ip_pool.py        # 代理池测试
│   ├── test_redis_cache.py          # Redis缓存测试
│   └── test_utils.py                # 工具函数测试
├── tools/                   # 通用工具函数
│   ├── browser_launcher.py # 浏览器启动器
│   ├── cdp_browser.py      # CDP浏览器控制
│   ├── crawler_util.py     # 爬虫工具
│   ├── easing.py           # 缓动函数
│   ├── slider_util.py      # 滑块验证工具
│   ├── time_util.py        # 时间工具
│   ├── utils.py            # 通用工具
│   └── words.py            # 词汇处理
├── var.py                   # 全局变量
├── .gitattributes          # Git属性配置
├── .github/                 # GitHub Actions 配置
├── .gitignore              # Git忽略文件配置
├── .python-version          # Python 版本指定(uv)
├── .venv/                   # Python 虚拟环境
├── .docs_site/              # 项目文档站点(vitepress)
├── LICENSE                  # 项目许可证
├── mypy.ini                 # Mypy 配置
├── pyproject.toml           # 项目依赖和元数据
├── recv_sms.py              # 短信接收相关脚本
├── requirements.txt         # Python 依赖列表
├── uv.lock                  # uv 锁文件
└── README.md                # 项目说明文档
```

## 核心模块详解

### API模块 (`api/`)

API模块是项目的核心服务层，基于FastAPI框架构建，提供RESTful API接口。

主要文件：
- `api.py`：API服务主入口，定义了所有API路由和处理函数
- `extra_sqlite_api.py`：SQLite数据库相关API扩展
- `extra_mysql_api.py`：MySQL数据库相关API扩展
- `api_run.bat`：API服务启动脚本

主要功能：
- 爬虫任务管理（同步/异步执行、状态查询）
- 数据库管理（表查询、数据导出、配置获取）
- 健康检查和服务监控

### 前端模块 (`frontend/`)

前端模块基于Vue.js和Vite构建，提供用户界面。

主要目录：
- `src/`：前端源代码
  - `api/`：API接口封装
  - `components/`：Vue组件
  - `views/`：页面视图
  - `router/`：路由配置
  - `stores/`：状态管理
  - `styles/`：样式文件
- `public/`：静态资源

主要功能：
- 数据爬取界面：配置和启动爬虫任务
- 数据展示界面：查看和导出爬取的数据

### 数据库操作模块 (`dp_op/`)

数据库操作模块封装了对SQLite和MySQL数据库的异步操作。

主要文件：
- `async_sqlite_db.py`：SQLite数据库异步操作封装
- `async_mysql_db.py`：MySQL数据库异步操作封装

### 媒体平台模块 (`media_platform/`)

媒体平台模块包含各个社交媒体平台的爬虫实现。

主要子目录：
- `bilibili/`：B站爬虫
- `douyin/`：抖音爬虫
- `kuaishou/`：快手爬虫
- `tieba/`：百度贴吧爬虫
- `weibo/`：微博爬虫
- `xhs/`：小红书爬虫
- `zhihu/`：知乎爬虫

每个平台子目录通常包含：
- 搜索爬虫实现
- 详情页爬虫实现
- 创作者/用户爬虫实现
- 平台特定的工具函数

### 数据模型模块 (`model/`)

数据模型模块定义了各平台数据的结构模型。

主要文件：
- `m_baidu_tieba.py`：百度贴吧数据模型
- `m_douyin.py`：抖音数据模型
- `m_kuaishou.py`：快手数据模型
- `m_weibo.py`：微博数据模型
- `m_xiaohongshu.py`：小红书数据模型
- `m_zhihu.py`：知乎数据模型

### 数据存储模块 (`store/`)

数据存储模块负责将爬取的数据保存到数据库。

主要子目录：
- `bilibili/`：B站数据存储
- `douyin/`：抖音数据存储
- `kuaishou/`：快手数据存储
- `tieba/`：百度贴吧数据存储
- `weibo/`：微博数据存储
- `xhs/`：小红书数据存储
- `zhihu/`：知乎数据存储

### 配置模块 (`config/`)

配置模块包含项目的全局配置。

主要文件：
- `base_config.py`：基础配置，包括平台选择、爬取类型、登录方式等
- `db_config.py`：数据库配置，包括MySQL和SQLite连接参数

### 命令行参数模块 (`cmd_arg/`)

命令行参数模块处理命令行输入参数。

主要文件：
- `arg.py`：参数解析器，定义了所有支持的命令行参数

### 数据库表结构 (`schema/`)

数据库表结构模块定义了数据库表的创建脚本。

主要文件：
- `sqlite_tables.sql`：SQLite数据库表结构定义
- `mysql_tables.sql`：MySQL数据库表结构定义
- `sqlite_tables.db`：SQLite数据库文件

### 工具模块 (`tools/`)

工具模块包含各种通用工具函数。

主要文件：
- `browser_launcher.py`：浏览器启动器
- `cdp_browser.py`：CDP浏览器控制
- `crawler_util.py`：爬虫工具
- `slider_util.py`：滑块验证工具
- `time_util.py`：时间工具
- `utils.py`：通用工具

### 缓存模块 (`cache/`)

缓存模块提供数据缓存功能。

主要文件：
- `abs_cache.py`：抽象缓存类
- `cache_factory.py`：缓存工厂
- `local_cache.py`：本地缓存实现
- `redis_cache.py`：Redis缓存实现

### 代理模块 (`proxy/`)

代理模块提供代理IP管理功能。

主要文件：
- `base_proxy.py`：代理基类
- `proxy_ip_pool.py`：代理IP池
- `types.py`：代理类型定义

## 主要入口文件

- `main.py`：爬虫主入口，命令行方式启动爬虫
- `api/api.py`：API服务主入口
- `db_init.py`：数据库初始化脚本

## 数据流向

1. **用户请求**：通过前端界面或API接口发起爬虫任务
2. **任务处理**：API服务创建并管理爬虫任务
3. **数据爬取**：相应平台的爬虫模块执行数据采集
4. **数据存储**：存储模块将数据保存到SQLite或MySQL数据库
5. **数据查询**：通过API接口查询和导出数据
6. **数据展示**：前端界面展示爬取的数据和统计信息

## 扩展点

项目设计了多个扩展点，便于添加新功能：

1. **新平台支持**：在`media_platform/`目录下添加新平台的爬虫实现
2. **新数据模型**：在`model/`目录下添加新平台的数据模型
3. **新存储方式**：在`store/`目录下添加新平台的数据存储逻辑
4. **新API接口**：在`api/api.py`中添加新的API路由和处理函数
5. **新前端功能**：在`frontend/src/`目录下添加新的组件和视图